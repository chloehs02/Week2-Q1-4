{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78c12010",
   "metadata": {},
   "source": [
    "# Learning Outcomes\n",
    "1. Gentle intro on CV\n",
    "2. Review on some important notion of image arrays\n",
    "3. Cropping (one of the data augmentation techniques employed in DL model training)\n",
    "4. Slit and merge image channels\n",
    "5. Point operators (basic mathematical operations) / gamma correction\n",
    "    * Aims: Enhance / Reduce the contrast or illumination of the images.\n",
    "6. Image blending (add 2 images together)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7861a733",
   "metadata": {},
   "source": [
    "## setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54eb89ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "assert sys.version_info >= (3, 7)\n",
    "\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from util_func import show_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8563d823",
   "metadata": {},
   "source": [
    "## review: important concepts on image arrays\n",
    "Images can be broadly categorized as **grayscale** and **color** images.\n",
    "\n",
    "| Grayscale | Color |\n",
    "| -:- | -:- |\n",
    "| matrix (2D array) | 3D array (channels) |\n",
    "| (h, w) | (h, w, channels) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c7b3ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0]\n",
      " [0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "img = np.zeros((2, 4), dtype = np.uint8)\n",
    "print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3c08d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]]\n"
     ]
    }
   ],
   "source": [
    "img_bgr = cv.cvtColor(img, cv.COLOR_GRAY2BGR)\n",
    "print(img_bgr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9a04c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0  30   0   0]\n",
      " [  0   0 100   0]]\n"
     ]
    }
   ],
   "source": [
    "#change value in array\n",
    "\n",
    "img[0, 1] = 30    #index of first row of array is 0\n",
    "img[1, 2] = 100\n",
    "print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "421b944c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[  0   0   0]\n",
      "  [ 30  30  30]\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]]\n",
      "\n",
      " [[  0   0   0]\n",
      "  [  0   0   0]\n",
      "  [100 100 100]\n",
      "  [  0   0   0]]]\n"
     ]
    }
   ],
   "source": [
    "img_bgr = cv.cvtColor(img, cv.COLOR_GRAY2BGR)   #all the values same will only output white, gray or black color\n",
    "print(img_bgr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124ee083",
   "metadata": {},
   "source": [
    "## Accessing pixel elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e103f9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv.imread(\"images/lena.jfif\")\n",
    "\n",
    "a = img[50, 70, 0]\n",
    "b = img.item(50, 70, 0)\n",
    "a == b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "432e884b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179 ns ± 12.2 ns per loop (mean ± std. dev. of 7 runs, 1,000,000 loops each)\n",
      "172 ns ± 4 ns per loop (mean ± std. dev. of 7 runs, 10,000,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit a = img[50, 70, 0]\n",
    "%timeit b = img.item(50, 70, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c0e69e",
   "metadata": {},
   "source": [
    "The takeaway the execution time is more or less the same. You are free to use either one of this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab06ffc2",
   "metadata": {},
   "source": [
    "## Numpy slicing (IMPORTANT!!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59987284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the top lft region of the image\n",
    "yc, xc = img.shape[0] // 2, img.shape[1] // 2\n",
    "\n",
    "topleft = img[:yc, :xc]  # slicing\n",
    "\n",
    "show_img(\"topleft\", topleft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70efda37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the middle region of the image\n",
    "\n",
    "middle = img[yc-30:yc+30, xc-30:xc+30]\n",
    "\n",
    "show_img(\"middle\", middle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b68e92ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a white image\n",
    "white = np.zeros((200, 200)) + 255\n",
    "white = np.uint8(white)\n",
    "show_img(\"white\", white)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ac8961",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7adcc85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2: design pattern\n",
    "\n",
    "patch = np.zeros((30, 30), dtype=np.uint8)\n",
    "\n",
    "patch[:10, 10:20] = 255\n",
    "patch[10:20, :10] = 255\n",
    "patch[10:20, 20:] = 255\n",
    "patch[20:, 10:20] = 255\n",
    "\n",
    "img = np.tile(patch, (3, 3))\n",
    "\n",
    "show_img(\"img\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ee58614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3: extract object of interest\n",
    "img = cv.imread(\"images/flower.jfif\")\n",
    "\n",
    "show_img(\"img\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0cc3f618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EVENT_FLAG_ALTKEY',\n",
       " 'EVENT_FLAG_CTRLKEY',\n",
       " 'EVENT_FLAG_LBUTTON',\n",
       " 'EVENT_FLAG_MBUTTON',\n",
       " 'EVENT_FLAG_RBUTTON',\n",
       " 'EVENT_FLAG_SHIFTKEY',\n",
       " 'EVENT_LBUTTONDBLCLK',\n",
       " 'EVENT_LBUTTONDOWN',\n",
       " 'EVENT_LBUTTONUP',\n",
       " 'EVENT_MBUTTONDBLCLK',\n",
       " 'EVENT_MBUTTONDOWN',\n",
       " 'EVENT_MBUTTONUP',\n",
       " 'EVENT_MOUSEHWHEEL',\n",
       " 'EVENT_MOUSEMOVE',\n",
       " 'EVENT_MOUSEWHEEL',\n",
       " 'EVENT_RBUTTONDBLCLK',\n",
       " 'EVENT_RBUTTONDOWN',\n",
       " 'EVENT_RBUTTONUP']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in dir(cv) if i.startswith('EVENT')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98ee8d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 way:\n",
    "def select_rect(img, x, y, flags, params):\n",
    "    \"\"\"mouseclick callback function\"\"\"\n",
    "    if event == cv.EVENT_LBUTTONDOWN:\n",
    "        print((x,y))\n",
    "        cv.circle(img, (x, y), 1, (0, 0, 255), -1)\n",
    "        cv.imshow(\"img\", img)\n",
    "\n",
    "img = cv.imread(\"images/flower.jfif\")\n",
    "cv.imshow(\"img\", img)\n",
    "cv.setMouseCallback(\"img\", select_rect)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3d7870",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 way:\n",
    "bbox = cv.selectROI('flower_region', img)  #window name can set it ourselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ca7dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 way:\n",
    "# top left coordinates: (91, 38) and bottom right coordinates: (170, 120)\n",
    "flower = img[38:120, 91:170]\n",
    "\n",
    "show_img(\"flower\", flower)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2fa377",
   "metadata": {},
   "source": [
    "## Image cropping\n",
    "In terms of operations, it is identical to slicing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e620935e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"images/dog.jfif\")\n",
    "img_copy = img.copy()\n",
    "\n",
    "h, w = img.shape[:2]\n",
    "n_vertical_grids = 3\n",
    "n_horizontal_grids = 3\n",
    "\n",
    "# row sizes and column sizes\n",
    "M = int(h / n_vertical_grids)\n",
    "N = int(w / n_horizontal_grids)\n",
    "\n",
    "tiles = []\n",
    "\n",
    "for y in range(0, h, M):\n",
    "    for x in range(0, w, N):\n",
    "        x1 = x + N\n",
    "        y1 = y + M\n",
    "        \n",
    "        if x1 > w and y1 > h:\n",
    "            x1 = w - 1\n",
    "            y1 = h - 1\n",
    "            cv.rectangle(img_copy, (x, y), (x1, y1), (0, 255, 0), 1)   #green rectangle\n",
    "            tile = img[y:h, x:w]\n",
    "            tiles.append(tile)\n",
    "        \n",
    "        elif y1 > h:\n",
    "            y1 = h - 1\n",
    "            cv.rectangle(img_copy, (x, y), (x1, y1), (0, 255, 0), 1)\n",
    "            tile = img[y:h, x:x1]\n",
    "            tiles.append(tile)\n",
    "        \n",
    "        elif x1 > w:\n",
    "            x1 = w - 1\n",
    "            cv.rectangle(img_copy, (x, y), (x1, y1), (0, 255, 0), 1)\n",
    "            tile = img[y:y1, x:w]\n",
    "            tiles.append(tile)\n",
    "        \n",
    "        else:\n",
    "            cv.rectangle(img_copy, (x, y), (x1, y1), (0, 255, 0), 1)\n",
    "            tile = img[y:y1, x:x1]\n",
    "            tiles.append(tile)\n",
    "            \n",
    "show_img(\"crop\", img_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75305f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img(\"top right\", tiles[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a2d20b",
   "metadata": {},
   "source": [
    "## Swapping region (exercise 1) - image cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea128a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1:\n",
    "img_array = np.zeros_like(img)\n",
    "\n",
    "yc, xc = img.shape[0] // 2, img.shape[1] // 2\n",
    "\n",
    "img_array[:yc, :xc] = img[yc:, xc:]\n",
    "img_array[yc:, xc:] = img[:yc, :xc]\n",
    "img_array[yc:, :xc] = img[:yc, xc:]\n",
    "img_array[:yc, xc:] = img[yc:, :xc]\n",
    "\n",
    "show_img(\"swap\", img_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d3a269",
   "metadata": {},
   "source": [
    "## Split and merge color channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c069da",
   "metadata": {},
   "outputs": [],
   "source": [
    "b, g, r = cv.split(img)\n",
    "img_merge = cv.merge((b, g, r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b571d36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array_equal(img, img_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86412366",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01f1f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"images/lena.jfif\")\n",
    "\n",
    "b, g, r = cv.split(img)\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(12, 4), sharey=True)\n",
    "fig.suptitle(\"different color channels\")\n",
    "ax1.imshow(b, cmap=plt.cm.gray)\n",
    "ax1.set(title=\"blue channel\", xticks=[], yticks=[])\n",
    "ax1.imshow(g, cmap=plt.cm.gray)\n",
    "ax1.set(title=\"green channel\", xticks=[], yticks=[])\n",
    "ax1.imshow(r, cmap=plt.cm.gray)\n",
    "ax1.set(title=\"red channel\", xticks=[], yticks=[])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc98c2b",
   "metadata": {},
   "source": [
    "### Exercise no 2: color channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8deaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"images/dog.jfif\")\n",
    "\n",
    "channels = cv.split(img)\n",
    "\n",
    "colors = (\"blue\", \"green\", \"red\")\n",
    "\n",
    "imgs = []\n",
    "\n",
    "for i, mat in enumerate(channels):\n",
    "    arr = np.zeros_like(img)\n",
    "    arr[:, :, i] = mat\n",
    "    imgs.append(arr)\n",
    "    \n",
    "for c, img in zip(colors, imgs):\n",
    "    cv.imshow(c, img)\n",
    "    \n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827e9df9",
   "metadata": {},
   "source": [
    "## Point operators\n",
    "$$ftrans(\\textbf{x}) = \\alpha f(\\textbf{x}) + \\beta$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f28fb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([-2, 0, 99, 260], dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ccda19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_op(img, alpha, beta):\n",
    "    \"\"\"point operators. Arguments\n",
    "    1. Source image\n",
    "    2. multiplier\n",
    "    3. constant\"\"\"\n",
    "    img = img.astype(float)\n",
    "    res = alpha * img + beta\n",
    "    res = np.clip(res, 0, 255)\n",
    "    res = np.uint8(res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d337a252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# increase the brightness and contrast of image\n",
    "img = cv.imread(\"images/bridge.jfif\")\n",
    "\n",
    "transform = point_op(img, 2, 30)\n",
    "\n",
    "cv.imshow(\"original\", img)\n",
    "show_img(\"transform\", transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0329657",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform2 = point_op(img, 0.8, -20)\n",
    "\n",
    "show_img(\"img_transform\", transform2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2646e390",
   "metadata": {},
   "source": [
    "## Gamma correction\n",
    "$$O = (\\frac{I}{255})^{\\gamma}\\times255$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf02e287",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 1 / 2.2\n",
    "\n",
    "lookUpTable = np.empty((1, 256), dtype=np.uint8)\n",
    "for i in range(256):\n",
    "    lookUpTable[0, i] = np.clip(pow(i / 255.0, gamma) * 255, 0, 255)\n",
    "    \n",
    "img = cv.imread(\"images/mountains_prop.jpg\")\n",
    "res = cv.LUT(img, lookUpTable)\n",
    "\n",
    "cv.namedWindow(\"original\", cv.WINDOW_NORMAL)\n",
    "cv.imshow(\"original\", img)\n",
    "show_img(\"gamma corrected\", res, adjust=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff087bca",
   "metadata": {},
   "source": [
    "## Image blending (add 2 images)\n",
    "$$h(\\textbf{x}) = \\alpha f(\\textbf{x}) + (1 - \\alpha)g(\\textbf{x}) + \\beta$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51671af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"images/lena.jfif\")\n",
    "img2 = cv.imread(\"images/coins.jfif\")\n",
    "\n",
    "alpha = 0.6\n",
    "h, w = img.shape[:2]\n",
    "img2 = cv.resize(img2, (w, h))\n",
    "\n",
    "res = cv.addWeighted(img, alpha, img2, 1-alpha, 0)\n",
    "\n",
    "cv.imshow(\"img1\", img)\n",
    "cv.imshow(\"img2\", img2)\n",
    "show_img(\"blending\", res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83f8feaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Define the width and height of the images\n",
    "width = 400\n",
    "height = 300\n",
    "\n",
    "# Calculate the total number of pixels\n",
    "total_pixels = width * height\n",
    "\n",
    "# Generate random noise color image\n",
    "color_image = np.random.randint(0, 256, (height, width, 3), dtype=np.uint8)\n",
    "\n",
    "# Generate random noise grayscale image\n",
    "grayscale_image = np.random.randint(0, 256, (height, width), dtype=np.uint8)\n",
    "\n",
    "# Display the color image\n",
    "cv2.imshow(\"Color Image\", color_image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Display the grayscale image\n",
    "cv2.imshow(\"Grayscale Image\", grayscale_image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "498ab6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def crop_grid(img, num_horizontal_grid, num_vertical_grid, line_color):\n",
    "    # Get the dimensions of the image\n",
    "    height, width = img.shape[:2]\n",
    "\n",
    "    # Calculate the size of each grid patch\n",
    "    patch_width = width // num_horizontal_grid\n",
    "    patch_height = height // num_vertical_grid\n",
    "\n",
    "    # Create a copy of the image\n",
    "    img_with_grid = img.copy()\n",
    "\n",
    "    # Draw vertical grid lines\n",
    "    for i in range(1, num_horizontal_grid):\n",
    "        x = patch_width * i\n",
    "        cv2.line(img_with_grid, (x, 0), (x, height), line_color, 1)\n",
    "\n",
    "    # Draw horizontal grid lines\n",
    "    for i in range(1, num_vertical_grid):\n",
    "        y = patch_height * i\n",
    "        cv2.line(img_with_grid, (0, y), (width, y), line_color, 1)\n",
    "\n",
    "    return img_with_grid\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread(\"images/dog.jfif\")\n",
    "\n",
    "# Define the number of grid patches and line color\n",
    "num_horizontal_grid = 3\n",
    "num_vertical_grid = 2\n",
    "line_color = (0, 255, 0)  # Green color (BGR format)\n",
    "\n",
    "# Crop the image into a grid with lines\n",
    "image_with_grid = crop_grid(image, num_horizontal_grid, num_vertical_grid, line_color)\n",
    "\n",
    "# Display the image with grid\n",
    "cv2.imshow(\"Image with Grid\", image_with_grid)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edbbef7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def blend_images(image1, image2, alpha):\n",
    "    # Resize the images to have the same dimensions (optional)\n",
    "    image1 = cv2.resize(image1, (500, 500))\n",
    "    image2 = cv2.resize(image2, (500, 500))\n",
    "    \n",
    "    # Perform image blending\n",
    "    blended_image = cv2.addWeighted(image1, alpha, image2, 1 - alpha, 0)\n",
    "    \n",
    "    return blended_image\n",
    "\n",
    "# Load the base images\n",
    "image1 = cv2.imread(\"images/lena.jfif\")\n",
    "image2 = cv2.imread(\"images/coins.jfif\")\n",
    "\n",
    "# Create a window to display the images\n",
    "cv2.namedWindow(\"Image Blending\", cv2.WINDOW_NORMAL)\n",
    "\n",
    "# Loop for blending images with different alpha values\n",
    "for alpha in np.linspace(0, 1, 100):\n",
    "    blended = blend_images(image1, image2, alpha)\n",
    "    \n",
    "    # Display the blended image\n",
    "    cv2.imshow(\"Image Blending\", blended)\n",
    "    \n",
    "    # Wait for a small delay between frames\n",
    "    cv2.waitKey(30)\n",
    "\n",
    "# Wait until a key is pressed to close the window\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Close all windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2f3827d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q4\n",
    "#Using putText to insert 'watermark' into image\n",
    "img = cv.imread(\"images/travel_hd.jpg\")\n",
    "\n",
    "if img is None:\n",
    "    raise Exception(\"Image not found\")\n",
    "    \n",
    "img = cv.resize(img,None,fx=0.1,fy=0.1)\n",
    "\n",
    "font= cv.FONT_HERSHEY_SIMPLEX\n",
    "y,x = img.shape[:2]\n",
    "res = cv.putText(img,\"UCCC2513 watermark\",(0,y-50),font,1,(255,255,255),2)\n",
    "show_img(\"watermark image\",res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
